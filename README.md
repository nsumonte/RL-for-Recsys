# Recursos de Aprendizaje reforzado para sistemas de recomendación.

- Lista de papers, codigo, datasets y otros recursos relacionado con el aprendizaje reforzado y los sistemas de recomendación (Algunos incluyen el link para el PDF, código y dataset).

# Artículos
[P1]  Session-aware Item-combination Recommendation with Transformer Network [[PDF]](https://arxiv.org/pdf/2111.08817.pdf)

> [Lin, T. H.](https://arxiv.org/search/cs?searchtype=author&query=Lin%2C+T), & [Gao, C.](https://arxiv.org/search/cs?searchtype=author&query=Gao%2C+C) (2021, December). Session-aware Item-combination Recommendation with Transformer Network. In 2021 IEEE International Conference on Big Data (Big Data) (pp. 5708-5713). IEEE.

[P2]  RecSim NG: Toward Principled Uncertainty Modeling for Recommender Ecosystems [[PDF]](https://arxiv.org/pdf/2103.08057.pdf)

> [Mladenov, M.](https://arxiv.org/search/cs?searchtype=author&query=Mladenov%2C+M), [Hsu, C.](https://arxiv.org/search/cs?searchtype=author&query=Hsu%2C+C), [Jain, V.](https://arxiv.org/search/cs?searchtype=author&query=Jain%2C+V), [Ie, E.](https://arxiv.org/search/cs?searchtype=author&query=Ie%2C+E), [Colby, C.](https://arxiv.org/search/cs?searchtype=author&query=Colby%2C+C), [Mayoraz, N.](https://arxiv.org/search/cs?searchtype=author&query=Mayoraz%2C+N), [Pham, H.](https://arxiv.org/search/cs?searchtype=author&query=Pham%2C+H), [Tran, D.](https://arxiv.org/search/cs?searchtype=author&query=Tran%2C+D), [Vendrov, I.](https://arxiv.org/search/cs?searchtype=author&query=Vendrov%2C+I) & [Boutilier, C.](https://arxiv.org/search/cs?searchtype=author&query=Boutilier%2C+C) (2021). RecSim NG: Toward Principled Uncertainty Modeling for Recommender Ecosystems. arXiv preprint arXiv:2103.08057.

[P3]  A Contextual-Bandit Approach to Personalized News Article Recommendation [[PDF]](https://arxiv.org/pdf/1003.0146.pdf)

> [Li, L.](https://arxiv.org/search/cs?searchtype=author&query=Li%2C+L), [Chu, W.](https://arxiv.org/search/cs?searchtype=author&query=Chu%2C+W), [Langford, J.](https://arxiv.org/search/cs?searchtype=author&query=Langford%2C+J), & [Schapire, R. E.](https://arxiv.org/search/cs?searchtype=author&query=Schapire%2C+R+E) (2010, April). A contextual-bandit approach to personalized news article recommendation. In Proceedings of the 19th international conference on World wide web (pp. 661-670).

[P4] Partially Observable Reinforcement Learning for Dialog-based Interactive Recommendation [[PDF]](https://dl.acm.org/doi/10.1145/3460231.3474256)

> Wu, Y., Macdonald, C., & Ounis, I. (2021, September). Partially Observable Reinforcement Learning for Dialog-based Interactive Recommendation. In Fifteenth ACM Conference on Recommender Systems (pp. 241-251).

[P5] Reinforcement Learning over Sentiment-Augmented Knowledge Graphs towards Accurate and Explainable Recommendation WSDM'22 [[PDF]](https://dl.acm.org/doi/abs/10.1145/3488560.3498515)

> Park, S. J., Chae, D. K., Bae, H. K., Park, S., & Kim, S. W. (2022, February). Reinforcement Learning over Sentiment-Augmented Knowledge Graphs towards Accurate and Explainable Recommendation. In Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining (WSDM'22) (pp. 784-793).

[P6] Improving Daily Deals Recommendation Using Explore-Then-Exploit Strategies [[PDF]](https://homepages.dcc.ufmg.br/~rodrygo/wp-content/papercite-data/pdf/lacerda2015irj.pdf)

> Lacerda, A., Santos, R. L., Veloso, A., & Ziviani, N. (2015). Improving daily deals recommendation using explore-then-exploit strategies. Information Retrieval Journal, 18(2), 95-122.

[P7]  Scalable explore-exploit collaborative filtering. [[PDF]](https://hal.inria.fr/hal-01406418)

> [Guillou, F.](https://hal.inria.fr/search/index/q/*/authFullName_s/Fr%C3%A9d%C3%A9ric+Guillou), [Gaudel, R.](https://hal.inria.fr/search/index/q/*/authIdHal_s/romaric-gaudel), & [Preux, P.](https://hal.inria.fr/search/index/q/*/authIdHal_s/preux-philippe) (2016). Scalable explore-exploit collaborative filtering. In Pacific Asia Conference on Information Systems (PACIS'16).

[P8] Factorization Bandits for Interactive Recommendation. [[PDF]](https://www.cs.virginia.edu/~hw5x/paper/factorUCB.pdf)

> Wang, H., Wu, Q., & Wang, H. (2017, February). Factorization bandits for interactive recommendation. In Thirty-First AAAI Conference on Artificial Intelligence.

[P9] Bandits and Recommender Systems. [[PDF]](https://hal.inria.fr/hal-01256033/file/Bandits_and_Recommender_Systems.pdf)

> Mary, J., Gaudel, R., & Preux, P. (2015, July). Bandits and recommender systems. In International Workshop on Machine Learning, Optimization and Big Data (pp. 325-336). Springer, Cham.

[P10] Adaptive, personalized diversity for visual discovery. [[PDF]](https://arxiv.org/pdf/1810.01477.pdf)

> Teo, C. H., Nassif, H., Hill, D., Srinivasan, S., Goodman, M., Mohan, V., & Vishwanathan, S. V. N. (2016, September). Adaptive, personalized diversity for visual discovery. In Proceedings of the 10th ACM conference on recommender systems (pp. 35-38).

[P11] Online clustering of bandits. [[PDF]](http://proceedings.mlr.press/v32/gentile14.pdf)

> Gentile, C., Li, S., & Zappella, G. (2014, June). Online clustering of bandits. In International Conference on Machine Learning (pp. 757-765). PMLR.

[P12] Learning diverse rankings with multi-armed bandits. [[PDF]](https://dl.acm.org/doi/pdf/10.1145/1390156.1390255)

> Radlinski, F., Kleinberg, R., & Joachims, T. (2008, July). Learning diverse rankings with multi-armed bandits. In Proceedings of the 25th international conference on Machine learning (pp. 784-791).

[P13] A Fast Bandit Algorithm for Recommendations to Users with Heterogeneous Tastes [[PDF]](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/11/kss_aaai2013.pdf)

> Kohli, P., Salek, M., & Stoddard, G. (2013, June). A fast bandit algorithm for recommendation to users with heterogenous tastes. In Proceedings of the AAAI Conference on Artificial Intelligence (Vol. 27, No. 1, pp. 1135-1141).

[P14] Contextual combinatorial bandit and its application on diversified online recommendation. [[PDF]](http://www.chenshouyuan.com/papers/sdm14.pdf)

> Qin, L., Chen, S., & Zhu, X. (2014, April). Contextual combinatorial bandit and its application on diversified online recommendation. In Proceedings of the 2014 SIAM International Conference on Data Mining (pp. 461-469). Society for Industrial and Applied Mathematics.

[P15] A Multiple-Play Bandit Algorithm Applied to Recommender Systems. [[PDF]](https://www.aaai.org/ocs/index.php/FLAIRS/FLAIRS15/paper/download/10385/10364)

> Louëdec, J., Chevalier, M., Mothe, J., Garivier, A., & Gerchinovitz, S. (2015, April). A multiple-play bandit algorithm applied to recommender systems. In The Twenty-Eighth International Flairs Conference.

[P16] Top-k off-policy correction for a REINFORCE recommender system. [[PDF]](http://alexbeutel.com/papers/wsdm2019_reinforce_recs.pdf) [[Link Video Youtube]](https://www.youtube.com/watch?v=HEqQ2_1XRTs)

> Chen, M., Beutel, A., Covington, P., Jain, S., Belletti, F., & Chi, E. H. (2019, January). Top-k off-policy correction for a REINFORCE recommender system. In Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining (pp. 456-464).

[P17] Unified conversational recommendation policy learning via graph-based reinforcement learning [[PDF]](https://arxiv.org/abs/2105.09710)

> Deng, Y., Li, Y., Sun, F., Ding, B., & Lam, W. (2021, July). Unified conversational recommendation policy learning via graph-based reinforcement learning. In Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval (pp. 1431-1441).

[P18] When and Whom to Collaborate with in a Changing Environment: A Collaborative Dynamic Bandit Solution [[PDF]](https://arxiv.org/abs/2104.07150)

> Li, C., Wu, Q., & Wang, H. (2021, July). When and Whom to Collaborate with in a Changing Environment: A Collaborative Dynamic Bandit Solution. In Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval (pp. 1410-1419).

[P19] Cluster-Based Bandits: Fast Cold-Start for Recommender System New Users [[PDF]](https://www.scss.tcd.ie/Doug.Leith/pubs/sigir16.pdf)

> Shams, S., Anderson, D., & Leith, D. (2021, July). Cluster-Based Bandits: Fast Cold-Start for Recommender System New Users. In Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval (pp. 1613-1616).

[P20]  Comparison-based Conversational Recommender System with Relative Bandit Feedback [[PDF]](https://dl.acm.org/doi/abs/10.1145/3404835.3462920)

> Xie, Z., Yu, T., Zhao, C., & Li, S. (2021, July). Comparison-based Conversational Recommender System with Relative Bandit Feedback. In Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval (pp. 1400-1409).

# Datasets

ContentWise impressions: an industrial dataset with impressions included [[dataset repo]](https://github.com/ContentWise/contentwise-impressions)

>Pérez Maurera, F. B., Ferrari Dacrema, M., Saule, L., Scriminaci, M., & Cremonesi, P. (2020, October). ContentWise impressions: an industrial dataset with impressions included. In Proceedings of the 29th ACM International Conference on Information & Knowledge Management (pp. 3093-3100).

Goodreads:  meta-data of the books, user-book interactions (users' public shelves) and users' detailed book reviews.  [[dataset repo]](https://github.com/MengtingWan/goodreads)

> Wan, M., & McAuley, J. (2018, September). Item recommendation on monotonic behavior chains. In Proceedings of the 12th ACM conference on recommender systems (pp. 86-94).
> Wan, M., Misra, R., Nakashole, N., & McAuley, J. (2019). Fine-grained spoiler detection from large-scale review corpora. arXiv preprint arXiv:1905.13416.

Goodreads spoilers [[link]] (https://sites.google.com/eng.ucsd.edu/ucsdbookgraph/reviews)

> Wan, M., Misra, R., Nakashole, N., & McAuley, J. (2019). Fine-grained spoiler detection from large-scale review corpora. arXiv preprint arXiv:1905.13416.

Amazon Product Reviews (2018) [[dataset repo]](https://nijianmo.github.io/amazon/index.html)

> He, R., & McAuley, J. (2016, April). Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative filtering. In proceedings of the 25th international conference on world wide web (pp. 507-517).

Pinterest Fashion Compatibility [[dataset repo]](https://github.com/kang205/STL-Dataset)

> Kang, W. C., Kim, E., Leskovec, J., Rosenberg, C., & McAuley, J. (2019). Complete the look: Scene-based complementary product recommendation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 10532-10541).

Clothing Fit Data [[Modcloth dataset]](http://deepx.ucsd.edu/public/jmcauley/modcloth/modcloth_final_data.json.gz)

> Misra, R., Wan, M., & McAuley, J. (2018, September). Decomposing fit semantics for product size recommendation in metric spaces. In Proceedings of the 12th ACM Conference on Recommender Systems (pp. 422-426).

Product Exchange/Bartering Data [[dataset repo]](http://swapit.github.io)

> Rappaz, J., Vladarean, M. L., McAuley, J., & Catasta, M. (2017, February). Bartering books to beers: a recommender system for exchange platforms. In Proceedings of the Tenth ACM International Conference on Web Search and Data Mining (pp. 505-514).
> He, R., & McAuley, J. (2016, February). VBPR: visual bayesian personalized ranking from implicit feedback. In Proceedings of the AAAI Conference on Artificial Intelligence (Vol. 30, No. 1).

# Ambientes de Simulación

# RL para publicidad en línea

# Libros
[L1] Sutton, R. S., & Barto, A. G. (2018). Reinforcement learning: An introduction. MIT press. [[PDF]](https://www.andrew.cmu.edu/course/10-703/textbook/BartoSutton.pdf)


[L2]  Deep Learning on Graphs [[PDF]](https://web.njit.edu/~ym329/dlg_book/)

> [Wang, Y.](https://www.cse.msu.edu/~wangy206/), [Jin, W.](http://www.cse.msu.edu/~jinwei2/), [Ma, Y.](http://cse.msu.edu/~mayao4/), & [Tang, J](https://www.cse.msu.edu/~tangjili/). (2021). Deep learning on graphs. Cambridge university press. 

# Cursos

[C1] Curso completo REINFORCEMENT LEARNING AND OPTIMAL CONTROL [[LINK]](http://web.mit.edu/dimitrib/www/RLbook.html)

> Dimitri P. Bertsekas, 2022
